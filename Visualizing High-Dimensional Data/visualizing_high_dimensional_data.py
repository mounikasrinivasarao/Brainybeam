# -*- coding: utf-8 -*-
"""Visualizing High-Dimensional Data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GOOD7aJEYryLSkRHgZWi4kLff6DoQ8-2

**Wine Quality Dataset**

**Meta Data of Wine Quality Dataset:**
The Wine Quality Dataset contains physicochemical inputs and sensory-based output data for various wine samples. Input variables, such as fixed acidity, volatile acidity, and alcohol content, are measured through laboratory tests to determine the chemical composition of the wine.

These features directly influence the wine's overall flavor and quality. The output variable, quality, is scored based on sensory evaluations by wine experts, ranging from 0 to 10. This dataset is often used for machine learning tasks like regression and classification.

**Input Variables (Physicochemical Tests):**

**Fixed Acidity:**

**Description:** The non-volatile acids present in the wine, such as tartaric acid.

**Type:** Numeric (Continuous)

**Units:** g/dm³

**Range:** Typically between 4 and 16.

**Volatile Acidity:**

**Description:** The amount of acetic acid in the wine, which at too high levels can lead to an unpleasant vinegar taste.

**Type:** Numeric (Continuous)

**Units:** g/dm³

**Range:** Generally between 0.1 and 1.5.

**Citric Acid:**

**Description:** A weak organic acid found in citrus fruits; adds freshness and flavor.

**Type:** Numeric (Continuous)

**Units:** g/dm³

**Range:** Usually between 0 and 1.

**Residual Sugar:**

**Description:** The amount of sugar remaining after fermentation stops. Wines with higher residual sugar tend to be sweeter.

**Type:** Numeric (Continuous)

**Units:** g/dm³

**Range:** Can vary widely; most wines fall between 0.5 and 20 g/dm³.

**Chlorides:**

**Description:** The amount of salt in the wine, affecting taste and stability.

**Type:** Numeric (Continuous)

**Units:** g/dm³

**Range:** Generally between 0.01 and 0.2.

**Free Sulfur Dioxide:**

**Description:** The amount of SO2 that is not bound and remains in the wine as free molecules. This component helps prevent microbial growth and oxidation.

**Type:** Numeric (Continuous)

**Units:** mg/dm³

**Range:** Typically between 1 and 72.

**Total Sulfur Dioxide:**

**Description:** The total amount of SO2, both free and bound, used as a preservative.

**Type:** Numeric (Continuous)

**Units:** mg/dm³

**Range:** Commonly between 6 and 289.

**Density:**

**Description:** The density of the wine, influenced by the alcohol and sugar content.

**Type:** Numeric (Continuous)

**Units:** g/cm³

**Range:** Varies from 0.990 to 1.003.

**pH:**

**Description:** A measure of acidity or alkalinity of the wine.

**Type:** Numeric (Continuous)

**Units:** N/A (pH scale)

**Range:** Usually between 2.8 and 3.8.

**Sulphates:**

**Description:** A wine additive that can contribute to SO2 levels and acts as an antimicrobial and antioxidant.

**Type:** Numeric (Continuous)

**Units:** g/dm³

**Range:** Generally from 0.3 to 1.

**Alcohol:**

**Description:** The percentage of alcohol content in the wine.

**Type:** Numeric (Continuous)

**Units:** %

**Range:** Typically between 8 and 15%.

**Output Variable (Sensory Data):**

**Quality:**

**Description:** The quality of the wine, based on sensory evaluation by wine experts, scored on a scale from 0 (worst) to 10 (best).

**Type:** Numeric (Discrete)

**Units: Score**

**Range:** 0 to 10, although most scores range between 3 and 8.

**Import Libraries**
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/content/WineQT.csv'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

"""Check data samples"""

data=pd.read_csv('/content/WineQT.csv')

data.head()

data.shape

"""Features"""

feature_list = data.columns[:-1].values
label = [data.columns[-1]]

print ("Feature list:", feature_list)
print ("Label:", label)

"""Data statistics"""

data.info()

data.describe()

data['quality'].value_counts()

"""histogram plot"""

sns.set()

data.quality.hist()
plt.xlabel('Wine Quality')
plt.ylabel('Count')

data.hist(bins=50,figsize=(15,15))
# display histogram
plt.show()

"""Create test set"""

from sklearn.model_selection import train_test_split

train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)

"""Stratified sampling"""

data.quality.hist()
plt.xlabel('Wine Quality')
plt.ylabel('Count')

from sklearn.model_selection import StratifiedShuffleSplit
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in sss.split(data, data["quality"]):
  strat_train_set = data.loc[train_index]
  strat_test_set = data.loc[test_index]

train_index, test_index= next(sss.split(data, data["quality"]))
strat_train_set = data.loc[train_index]
strat_test_set = data.loc[test_index]

strat_train_set

strat_dist = strat_test_set["quality"].value_counts() / len(strat_test_set)

overall_dist = data["quality"].value_counts() / len(data)

dist_comparison = pd.DataFrame({'overall': overall_dist, 'stratified': strat_dist})
dist_comparison['diff(s-o)'] = dist_comparison['stratified'] - dist_comparison['overall']
dist_comparison['diff(s-o)_pct'] = 100*(dist_comparison['diff(s-o)']/dist_comparison['overall'])

dist_comparison

random_dist = test_set["quality"].value_counts() / len(test_set)
random_dist

dist_comparison['random'] = random_dist
dist_comparison['diff(r-o)'] = dist_comparison['random'] - dist_comparison['overall']
dist_comparison['diff(r-o)_pct'] = 100*(dist_comparison['diff(r-o)']/dist_comparison['overall'])

"""Sampling bias comparison"""

dist_comparison.loc[:, ['diff(s-o)_pct', 'diff(r-o)_pct']]

"""Data visualization"""

exploration_set = strat_train_set.copy()

sns.scatterplot(x='fixed acidity', y='density', hue='quality',
                data=exploration_set)

exploration_set.plot(kind='scatter', x='fixed acidity', y='density', alpha=0.5,
                     c="quality", cmap=plt.get_cmap("jet"))

corr_matrix = exploration_set.corr()

corr_matrix['quality']

plt.figure(figsize=(14,7))
sns.heatmap(corr_matrix, annot=True)

import warnings

# Suppress specific warnings
warnings.filterwarnings("ignore", category=FutureWarning, module="seaborn")

attribute_list = ['citric acid', 'pH', 'alcohol', 'sulphates', 'quality']
sns.pairplot(exploration_set[attribute_list])
plt.show()

from pandas.plotting import scatter_matrix
scatter_matrix(exploration_set[attribute_list])
plt.show()

"""Separate features and labels from the training set."""

wine_features = strat_train_set.drop("quality", axis=1)

wine_labels = strat_train_set['quality'].copy()

wine_features.isna().sum()

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="median")

imputer.fit(wine_features)

imputer.statistics_

wine_features.median()

tr_features = imputer.transform(wine_features)

tr_features.shape

"""Converting categories to numbers"""

from sklearn.preprocessing import OrdinalEncoder
ordinal_encoder = OrdinalEncoder()

from sklearn.preprocessing import OneHotEncoder
cat_encoder = OneHotEncoder()

"""Transformation Pipeline"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

transform_pipeline = Pipeline([
                               ('imputer', SimpleImputer(strategy="median")),
                               ('std_scaler', StandardScaler()),])
transform_pipeline

wine_features_tr = transform_pipeline.fit_transform(wine_features)

"""Select and train ML model"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(wine_features_tr, wine_labels)

from sklearn.metrics import mean_squared_error

quality_predictions =  lin_reg.predict(wine_features_tr)
mean_squared_error(wine_labels, quality_predictions)

wine_features_test = strat_test_set.drop("quality", axis=1)

wine_labels_test = strat_test_set['quality'].copy()

wine_features_test_tr = transform_pipeline.transform(wine_features_test)

quality_test_predictions = lin_reg.predict(wine_features_test_tr)
mean_squared_error(wine_labels_test, quality_test_predictions)

plt.scatter(wine_labels_test, quality_test_predictions)
plt.plot(wine_labels_test, wine_labels_test, 'r-')
plt.xlabel('Actual quality')
plt.ylabel('Predicted quality')

from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor()
tree_reg.fit(wine_features_tr, wine_labels)

quality_predictions =  tree_reg.predict(wine_features_tr)
mean_squared_error(wine_labels, quality_predictions)
0.0

quality_test_predictions = tree_reg.predict(wine_features_test_tr)
mean_squared_error(wine_labels_test, quality_test_predictions)

plt.scatter(wine_labels_test, quality_test_predictions)
plt.plot(wine_labels_test, wine_labels_test, 'r-')
plt.xlabel('Actual quality')
plt.ylabel('Predicted quality')

from sklearn.model_selection import cross_val_score

def display_scores(scores):
  print("Scores:", scores)
  print("Mean:", scores.mean())
  print("Standard deviation:", scores.std())

scores = cross_val_score(lin_reg, wine_features_tr, wine_labels,
                         scoring="neg_mean_squared_error", cv=10)
lin_reg_mse_scores = -scores
display_scores(lin_reg_mse_scores)

scores = cross_val_score(tree_reg, wine_features_tr, wine_labels,
                         scoring="neg_mean_squared_error", cv=10)
tree_mse_scores = -scores
display_scores(tree_mse_scores)

from sklearn.ensemble import RandomForestRegressor

forest_reg = RandomForestRegressor()
forest_reg.fit(wine_features_tr, wine_labels)

scores = cross_val_score(forest_reg, wine_features_tr, wine_labels,
                         scoring="neg_mean_squared_error", cv=10)
forest_mse_scores = -scores
display_scores(forest_mse_scores)

quality_test_predictions = forest_reg.predict(wine_features_test_tr)
mean_squared_error(wine_labels_test, quality_test_predictions)

plt.scatter(wine_labels_test, quality_test_predictions)
plt.plot(wine_labels_test, wine_labels_test, 'r-')
plt.xlabel('Actual quality')
plt.ylabel('Predicted quality')

"""Finetuning the models"""

from sklearn.model_selection import GridSearchCV

param_grid = [
 {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},
 {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},
]

grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
                           scoring='neg_mean_squared_error',
                           return_train_score=True)

grid_search.fit(wine_features_tr, wine_labels)

grid_search.best_params_

cvres = grid_search.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
  print(-mean_score, params)

grid_search.best_estimator_

"""Randomized Search"""

from sklearn.model_selection import RandomizedSearchCV

feature_importances = grid_search.best_estimator_.feature_importances_

sorted(zip(feature_importances, feature_list), reverse=True)

wine_features_test = strat_test_set.drop("quality", axis=1)

wine_labels_test = strat_test_set['quality'].copy()

wine_features_test_tr = transform_pipeline.transform(wine_features_test)

quality_test_predictions = grid_search.best_estimator_.predict(
    wine_features_test_tr)

mean_squared_error(wine_labels_test, quality_test_predictions)

from scipy import stats
confidence = 0.95
squared_errors = (quality_test_predictions - wine_labels_test) ** 2
stats.t.interval(confidence, len(squared_errors) - 1,
                 loc=squared_errors.mean(),
                 scale=stats.sem(squared_errors))